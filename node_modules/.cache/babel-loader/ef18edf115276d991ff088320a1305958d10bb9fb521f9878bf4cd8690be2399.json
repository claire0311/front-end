{"ast":null,"code":"import axios from 'axios';\n\n// 從環境變數讀取 API URL，若無則使用預設值\nconst OLLAMA_API_URL = process.env.REACT_APP_OLLAMA_API_URL || 'http://localhost:11434';\n\n/**\r\n * 發送訊息到 Ollama API (用於對話)\r\n * @param {string} goal 當前聊天目標\r\n * @param {Array<{role: 'user' | 'assistant', content: string}>} messages 包含歷史訊息的陣列\r\n * @param {{name: string, description: string}} character 當前選擇的角色\r\n * @param {string} model 要使用的 Ollama 模型名稱 (例如 'llama3')\r\n * @returns {Promise<string>} AI 回應的文字\r\n */\nexport const sendMessageToOllama = async (goal, messages, character, model = 'llama3') => {\n  const apiUrl = `${OLLAMA_API_URL}/api/chat`;\n\n  // 建構系統提示 (System Prompt)\n  const systemPrompt = `You are WingChat, an AI social coach.\nYour current persona is: ${character.name}.\nCharacter description: ${character.description}. Strictly adhere to this persona in your responses, including tone and style.\nThe user's current social training goal is: \"${goal}\".\nEngage in a conversation relevant to the user's goal, acting as the specified persona. Keep your responses concise, natural-sounding, and focused on the training objective. Avoid meta-commentary about being an AI unless it's part of the persona. Do not break character.`;\n\n  // 組合完整的訊息列表\n  const requestMessages = [{\n    role: 'system',\n    content: systemPrompt\n  }, ...messages // 包含 user 和 assistant 的歷史訊息\n  ];\n  try {\n    console.log(\"Sending message to Ollama:\", {\n      model,\n      messages: requestMessages\n    });\n    const response = await axios.post(apiUrl, {\n      model: model,\n      messages: requestMessages,\n      stream: false,\n      // 獲取完整回應\n      options: {\n        temperature: 0.7 // 稍微增加一點創意性\n        // num_ctx: 4096, // 可選：根據模型調整上下文窗口大小\n      }\n    }, {\n      timeout: 60000\n    }); // 增加超時時間 (60秒)\n\n    console.log(\"Ollama message response:\", response.data);\n    if (response.data && response.data.message && response.data.message.content) {\n      return response.data.message.content.trim();\n    } else {\n      console.error(\"Unexpected response structure:\", response.data);\n      throw new Error('從 Ollama API 收到的回應結構無效');\n    }\n  } catch (error) {\n    handleOllamaError(error, 'sendMessageToOllama'); // 使用統一的錯誤處理函數\n  }\n};\n\n/**\r\n * 向 Ollama 請求對話回饋\r\n * @param {string} goal 聊天目標\r\n * @param {Array<{role: 'user' | 'assistant', content: string}>} messages 對話歷史\r\n * @param {{name: string, description: string}} character 互動的角色\r\n * @param {string} model 模型名稱\r\n * @returns {Promise<string>} AI 回饋的文字 (包含分數和總結，需要前端解析或進一步處理)\r\n * @throws {Error} If the API call fails or returns an unexpected structure.\r\n */\nexport const getFeedbackFromOllama = async (goal, messages, character, model = 'llama3') => {\n  const apiUrl = `${OLLAMA_API_URL}/api/chat`;\n\n  // 構建一個用於請求回饋的 Prompt\n  // **重要**: 這個 Prompt 需要精心設計，讓 LLM 返回結構化的數據 (分數和總結)\n  // 這是一個範例，你可能需要多次實驗才能獲得好的結果\n  const feedbackPrompt = `You are an expert AI social skills evaluator. Analyze the following conversation where the user practiced the social goal \"${goal}\" while interacting with the persona \"${character.name}\" (${character.description}).\n\nConversation History:\n${messages.map(m => `${m.role === 'user' ? 'User' : character.name}: ${m.content}`).join('\\n')}\n\nBased *only* on the user's messages in the conversation history provided, please evaluate the user's performance according to the social goal \"${goal}\". Provide feedback focusing on the user's clarity, empathy, confidence, appropriateness, and goal achievement.\n\nOutput your feedback in the following format ONLY. Do not add any extra text before or after this structure:\n\n[Feedback Summary]\nProvide a concise summary (2-3 sentences) of the user's overall performance regarding the goal \"${goal}\". Mention specific strengths and areas for improvement based on their messages.\n\n[Scores]\nClarity: [Score from 0-100]\nEmpathy: [Score from 0-100, if applicable to the goal, otherwise N/A]\nConfidence: [Score from 0-100]\nAppropriateness: [Score from 0-100]\nGoal Achievement: [Score from 0-100, how well they addressed the core goal]\n\nProvide numerical scores only, without any explanation after the score number. If a category is not applicable (e.g., Empathy in a technical introduction), state N/A instead of a score.\n`;\n\n  // 只需要將 feedbackPrompt 作為 user message 發送給 AI\n  const requestMessages = [{\n    role: 'user',\n    content: feedbackPrompt\n  }];\n  try {\n    console.log(\"Sending feedback request to Ollama:\", {\n      model,\n      messages: requestMessages\n    });\n    const response = await axios.post(apiUrl, {\n      model: model,\n      // 可以使用能力更強的模型來做評估\n      messages: requestMessages,\n      stream: false,\n      options: {\n        temperature: 0.3 // 評估時降低隨機性\n        // num_ctx: 4096,\n      }\n    }, {\n      timeout: 90000\n    }); // 回饋請求可能需要更長時間\n\n    console.log(\"Ollama feedback response:\", response.data);\n    if (response.data && response.data.message && response.data.message.content) {\n      // 直接返回 AI 的原始回饋文本，前端需要解析\n      // **注意**: 前端需要 robust 地解析這個文本以提取分數和總結\n      return response.data.message.content.trim();\n    } else {\n      console.error(\"Unexpected feedback response structure:\", response.data);\n      throw new Error('從 Ollama API 收到的回饋回應結構無效');\n    }\n  } catch (error) {\n    handleOllamaError(error, 'getFeedbackFromOllama');\n  }\n};\n\n// 統一的錯誤處理函數\nfunction handleOllamaError(error, functionName) {\n  console.error(`Error in ${functionName}:`, error.response ? error.response.data : error.message);\n  let errorMessage = `與 AI (${functionName}) 通訊時發生錯誤。`;\n  if (error.code === 'ECONNABORTED') {\n    errorMessage = '連接 AI 超時，請稍後再試。';\n  } else if (error.response) {\n    // Ollama 返回了錯誤訊息\n    if (error.response.data && error.response.data.error) {\n      if (error.response.data.error.includes(\"model not found\")) {\n        var _error$config;\n        errorMessage = `AI 模型 '${(_error$config = error.config) !== null && _error$config !== void 0 && _error$config.data ? JSON.parse(error.config.data).model : 'specified'}' 未找到。請確認 Ollama 已下載該模型。`;\n      } else {\n        errorMessage = `Ollama API 錯誤: ${error.response.data.error}`;\n      }\n    } else {\n      errorMessage = `AI 伺服器錯誤 (狀態碼: ${error.response.status})。`;\n    }\n  } else if (error.request) {\n    // 請求已發出，但沒有收到回應\n    errorMessage = '無法連接到 AI 服務。請檢查 Ollama 是否正在運行以及網路連接是否正常。';\n  } else {\n    // 發生了其他錯誤\n    errorMessage = `發生未知錯誤: ${error.message}`;\n  }\n  throw new Error(errorMessage);\n}","map":{"version":3,"names":["axios","OLLAMA_API_URL","process","env","REACT_APP_OLLAMA_API_URL","sendMessageToOllama","goal","messages","character","model","apiUrl","systemPrompt","name","description","requestMessages","role","content","console","log","response","post","stream","options","temperature","timeout","data","message","trim","error","Error","handleOllamaError","getFeedbackFromOllama","feedbackPrompt","map","m","join","functionName","errorMessage","code","includes","_error$config","config","JSON","parse","status","request"],"sources":["C:/Users/Paul2/onedrive/桌面/llm_dialougue_v4/wingchat-app/src/services/ollamaService.js"],"sourcesContent":["import axios from 'axios';\r\n\r\n// 從環境變數讀取 API URL，若無則使用預設值\r\nconst OLLAMA_API_URL = process.env.REACT_APP_OLLAMA_API_URL || 'http://localhost:11434';\r\n\r\n/**\r\n * 發送訊息到 Ollama API (用於對話)\r\n * @param {string} goal 當前聊天目標\r\n * @param {Array<{role: 'user' | 'assistant', content: string}>} messages 包含歷史訊息的陣列\r\n * @param {{name: string, description: string}} character 當前選擇的角色\r\n * @param {string} model 要使用的 Ollama 模型名稱 (例如 'llama3')\r\n * @returns {Promise<string>} AI 回應的文字\r\n */\r\nexport const sendMessageToOllama = async (goal, messages, character, model = 'llama3') => {\r\n  const apiUrl = `${OLLAMA_API_URL}/api/chat`;\r\n\r\n  // 建構系統提示 (System Prompt)\r\n  const systemPrompt = `You are WingChat, an AI social coach.\r\nYour current persona is: ${character.name}.\r\nCharacter description: ${character.description}. Strictly adhere to this persona in your responses, including tone and style.\r\nThe user's current social training goal is: \"${goal}\".\r\nEngage in a conversation relevant to the user's goal, acting as the specified persona. Keep your responses concise, natural-sounding, and focused on the training objective. Avoid meta-commentary about being an AI unless it's part of the persona. Do not break character.`;\r\n\r\n  // 組合完整的訊息列表\r\n  const requestMessages = [\r\n    { role: 'system', content: systemPrompt },\r\n    ...messages // 包含 user 和 assistant 的歷史訊息\r\n  ];\r\n\r\n  try {\r\n    console.log(\"Sending message to Ollama:\", { model, messages: requestMessages });\r\n\r\n    const response = await axios.post(apiUrl, {\r\n      model: model,\r\n      messages: requestMessages,\r\n      stream: false, // 獲取完整回應\r\n      options: {\r\n         temperature: 0.7, // 稍微增加一點創意性\r\n         // num_ctx: 4096, // 可選：根據模型調整上下文窗口大小\r\n      }\r\n    }, { timeout: 60000 }); // 增加超時時間 (60秒)\r\n\r\n    console.log(\"Ollama message response:\", response.data);\r\n\r\n    if (response.data && response.data.message && response.data.message.content) {\r\n      return response.data.message.content.trim();\r\n    } else {\r\n      console.error(\"Unexpected response structure:\", response.data);\r\n      throw new Error('從 Ollama API 收到的回應結構無效');\r\n    }\r\n\r\n  } catch (error) {\r\n    handleOllamaError(error, 'sendMessageToOllama'); // 使用統一的錯誤處理函數\r\n  }\r\n};\r\n\r\n/**\r\n * 向 Ollama 請求對話回饋\r\n * @param {string} goal 聊天目標\r\n * @param {Array<{role: 'user' | 'assistant', content: string}>} messages 對話歷史\r\n * @param {{name: string, description: string}} character 互動的角色\r\n * @param {string} model 模型名稱\r\n * @returns {Promise<string>} AI 回饋的文字 (包含分數和總結，需要前端解析或進一步處理)\r\n * @throws {Error} If the API call fails or returns an unexpected structure.\r\n */\r\nexport const getFeedbackFromOllama = async (goal, messages, character, model = 'llama3') => {\r\n    const apiUrl = `${OLLAMA_API_URL}/api/chat`;\r\n\r\n    // 構建一個用於請求回饋的 Prompt\r\n    // **重要**: 這個 Prompt 需要精心設計，讓 LLM 返回結構化的數據 (分數和總結)\r\n    // 這是一個範例，你可能需要多次實驗才能獲得好的結果\r\n    const feedbackPrompt = `You are an expert AI social skills evaluator. Analyze the following conversation where the user practiced the social goal \"${goal}\" while interacting with the persona \"${character.name}\" (${character.description}).\r\n\r\nConversation History:\r\n${messages.map(m => `${m.role === 'user' ? 'User' : character.name}: ${m.content}`).join('\\n')}\r\n\r\nBased *only* on the user's messages in the conversation history provided, please evaluate the user's performance according to the social goal \"${goal}\". Provide feedback focusing on the user's clarity, empathy, confidence, appropriateness, and goal achievement.\r\n\r\nOutput your feedback in the following format ONLY. Do not add any extra text before or after this structure:\r\n\r\n[Feedback Summary]\r\nProvide a concise summary (2-3 sentences) of the user's overall performance regarding the goal \"${goal}\". Mention specific strengths and areas for improvement based on their messages.\r\n\r\n[Scores]\r\nClarity: [Score from 0-100]\r\nEmpathy: [Score from 0-100, if applicable to the goal, otherwise N/A]\r\nConfidence: [Score from 0-100]\r\nAppropriateness: [Score from 0-100]\r\nGoal Achievement: [Score from 0-100, how well they addressed the core goal]\r\n\r\nProvide numerical scores only, without any explanation after the score number. If a category is not applicable (e.g., Empathy in a technical introduction), state N/A instead of a score.\r\n`;\r\n\r\n    // 只需要將 feedbackPrompt 作為 user message 發送給 AI\r\n    const requestMessages = [\r\n        { role: 'user', content: feedbackPrompt }\r\n    ];\r\n\r\n    try {\r\n        console.log(\"Sending feedback request to Ollama:\", { model, messages: requestMessages });\r\n\r\n        const response = await axios.post(apiUrl, {\r\n            model: model, // 可以使用能力更強的模型來做評估\r\n            messages: requestMessages,\r\n            stream: false,\r\n            options: {\r\n               temperature: 0.3, // 評估時降低隨機性\r\n               // num_ctx: 4096,\r\n            }\r\n        }, { timeout: 90000 }); // 回饋請求可能需要更長時間\r\n\r\n        console.log(\"Ollama feedback response:\", response.data);\r\n\r\n        if (response.data && response.data.message && response.data.message.content) {\r\n            // 直接返回 AI 的原始回饋文本，前端需要解析\r\n            // **注意**: 前端需要 robust 地解析這個文本以提取分數和總結\r\n            return response.data.message.content.trim();\r\n        } else {\r\n            console.error(\"Unexpected feedback response structure:\", response.data);\r\n            throw new Error('從 Ollama API 收到的回饋回應結構無效');\r\n        }\r\n\r\n    } catch (error) {\r\n        handleOllamaError(error, 'getFeedbackFromOllama');\r\n    }\r\n};\r\n\r\n\r\n// 統一的錯誤處理函數\r\nfunction handleOllamaError(error, functionName) {\r\n    console.error(`Error in ${functionName}:`, error.response ? error.response.data : error.message);\r\n    let errorMessage = `與 AI (${functionName}) 通訊時發生錯誤。`;\r\n\r\n    if (error.code === 'ECONNABORTED') {\r\n        errorMessage = '連接 AI 超時，請稍後再試。';\r\n    } else if (error.response) {\r\n        // Ollama 返回了錯誤訊息\r\n        if (error.response.data && error.response.data.error) {\r\n            if (error.response.data.error.includes(\"model not found\")) {\r\n                 errorMessage = `AI 模型 '${error.config?.data ? JSON.parse(error.config.data).model : 'specified'}' 未找到。請確認 Ollama 已下載該模型。`;\r\n            } else {\r\n                errorMessage = `Ollama API 錯誤: ${error.response.data.error}`;\r\n            }\r\n        } else {\r\n            errorMessage = `AI 伺服器錯誤 (狀態碼: ${error.response.status})。`;\r\n        }\r\n    } else if (error.request) {\r\n        // 請求已發出，但沒有收到回應\r\n        errorMessage = '無法連接到 AI 服務。請檢查 Ollama 是否正在運行以及網路連接是否正常。';\r\n    } else {\r\n        // 發生了其他錯誤\r\n        errorMessage = `發生未知錯誤: ${error.message}`;\r\n    }\r\n    throw new Error(errorMessage);\r\n}"],"mappings":"AAAA,OAAOA,KAAK,MAAM,OAAO;;AAEzB;AACA,MAAMC,cAAc,GAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB,IAAI,wBAAwB;;AAEvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,mBAAmB,GAAG,MAAAA,CAAOC,IAAI,EAAEC,QAAQ,EAAEC,SAAS,EAAEC,KAAK,GAAG,QAAQ,KAAK;EACxF,MAAMC,MAAM,GAAG,GAAGT,cAAc,WAAW;;EAE3C;EACA,MAAMU,YAAY,GAAG;AACvB,2BAA2BH,SAAS,CAACI,IAAI;AACzC,yBAAyBJ,SAAS,CAACK,WAAW;AAC9C,+CAA+CP,IAAI;AACnD,8QAA8Q;;EAE5Q;EACA,MAAMQ,eAAe,GAAG,CACtB;IAAEC,IAAI,EAAE,QAAQ;IAAEC,OAAO,EAAEL;EAAa,CAAC,EACzC,GAAGJ,QAAQ,CAAC;EAAA,CACb;EAED,IAAI;IACFU,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAE;MAAET,KAAK;MAAEF,QAAQ,EAAEO;IAAgB,CAAC,CAAC;IAE/E,MAAMK,QAAQ,GAAG,MAAMnB,KAAK,CAACoB,IAAI,CAACV,MAAM,EAAE;MACxCD,KAAK,EAAEA,KAAK;MACZF,QAAQ,EAAEO,eAAe;MACzBO,MAAM,EAAE,KAAK;MAAE;MACfC,OAAO,EAAE;QACNC,WAAW,EAAE,GAAG,CAAE;QAClB;MACH;IACF,CAAC,EAAE;MAAEC,OAAO,EAAE;IAAM,CAAC,CAAC,CAAC,CAAC;;IAExBP,OAAO,CAACC,GAAG,CAAC,0BAA0B,EAAEC,QAAQ,CAACM,IAAI,CAAC;IAEtD,IAAIN,QAAQ,CAACM,IAAI,IAAIN,QAAQ,CAACM,IAAI,CAACC,OAAO,IAAIP,QAAQ,CAACM,IAAI,CAACC,OAAO,CAACV,OAAO,EAAE;MAC3E,OAAOG,QAAQ,CAACM,IAAI,CAACC,OAAO,CAACV,OAAO,CAACW,IAAI,CAAC,CAAC;IAC7C,CAAC,MAAM;MACLV,OAAO,CAACW,KAAK,CAAC,gCAAgC,EAAET,QAAQ,CAACM,IAAI,CAAC;MAC9D,MAAM,IAAII,KAAK,CAAC,wBAAwB,CAAC;IAC3C;EAEF,CAAC,CAAC,OAAOD,KAAK,EAAE;IACdE,iBAAiB,CAACF,KAAK,EAAE,qBAAqB,CAAC,CAAC,CAAC;EACnD;AACF,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMG,qBAAqB,GAAG,MAAAA,CAAOzB,IAAI,EAAEC,QAAQ,EAAEC,SAAS,EAAEC,KAAK,GAAG,QAAQ,KAAK;EACxF,MAAMC,MAAM,GAAG,GAAGT,cAAc,WAAW;;EAE3C;EACA;EACA;EACA,MAAM+B,cAAc,GAAG,8HAA8H1B,IAAI,yCAAyCE,SAAS,CAACI,IAAI,MAAMJ,SAAS,CAACK,WAAW;AAC/O;AACA;AACA,EAAEN,QAAQ,CAAC0B,GAAG,CAACC,CAAC,IAAI,GAAGA,CAAC,CAACnB,IAAI,KAAK,MAAM,GAAG,MAAM,GAAGP,SAAS,CAACI,IAAI,KAAKsB,CAAC,CAAClB,OAAO,EAAE,CAAC,CAACmB,IAAI,CAAC,IAAI,CAAC;AAC9F;AACA,iJAAiJ7B,IAAI;AACrJ;AACA;AACA;AACA;AACA,kGAAkGA,IAAI;AACtG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;EAEG;EACA,MAAMQ,eAAe,GAAG,CACpB;IAAEC,IAAI,EAAE,MAAM;IAAEC,OAAO,EAAEgB;EAAe,CAAC,CAC5C;EAED,IAAI;IACAf,OAAO,CAACC,GAAG,CAAC,qCAAqC,EAAE;MAAET,KAAK;MAAEF,QAAQ,EAAEO;IAAgB,CAAC,CAAC;IAExF,MAAMK,QAAQ,GAAG,MAAMnB,KAAK,CAACoB,IAAI,CAACV,MAAM,EAAE;MACtCD,KAAK,EAAEA,KAAK;MAAE;MACdF,QAAQ,EAAEO,eAAe;MACzBO,MAAM,EAAE,KAAK;MACbC,OAAO,EAAE;QACNC,WAAW,EAAE,GAAG,CAAE;QAClB;MACH;IACJ,CAAC,EAAE;MAAEC,OAAO,EAAE;IAAM,CAAC,CAAC,CAAC,CAAC;;IAExBP,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEC,QAAQ,CAACM,IAAI,CAAC;IAEvD,IAAIN,QAAQ,CAACM,IAAI,IAAIN,QAAQ,CAACM,IAAI,CAACC,OAAO,IAAIP,QAAQ,CAACM,IAAI,CAACC,OAAO,CAACV,OAAO,EAAE;MACzE;MACA;MACA,OAAOG,QAAQ,CAACM,IAAI,CAACC,OAAO,CAACV,OAAO,CAACW,IAAI,CAAC,CAAC;IAC/C,CAAC,MAAM;MACHV,OAAO,CAACW,KAAK,CAAC,yCAAyC,EAAET,QAAQ,CAACM,IAAI,CAAC;MACvE,MAAM,IAAII,KAAK,CAAC,0BAA0B,CAAC;IAC/C;EAEJ,CAAC,CAAC,OAAOD,KAAK,EAAE;IACZE,iBAAiB,CAACF,KAAK,EAAE,uBAAuB,CAAC;EACrD;AACJ,CAAC;;AAGD;AACA,SAASE,iBAAiBA,CAACF,KAAK,EAAEQ,YAAY,EAAE;EAC5CnB,OAAO,CAACW,KAAK,CAAC,YAAYQ,YAAY,GAAG,EAAER,KAAK,CAACT,QAAQ,GAAGS,KAAK,CAACT,QAAQ,CAACM,IAAI,GAAGG,KAAK,CAACF,OAAO,CAAC;EAChG,IAAIW,YAAY,GAAG,SAASD,YAAY,YAAY;EAEpD,IAAIR,KAAK,CAACU,IAAI,KAAK,cAAc,EAAE;IAC/BD,YAAY,GAAG,iBAAiB;EACpC,CAAC,MAAM,IAAIT,KAAK,CAACT,QAAQ,EAAE;IACvB;IACA,IAAIS,KAAK,CAACT,QAAQ,CAACM,IAAI,IAAIG,KAAK,CAACT,QAAQ,CAACM,IAAI,CAACG,KAAK,EAAE;MAClD,IAAIA,KAAK,CAACT,QAAQ,CAACM,IAAI,CAACG,KAAK,CAACW,QAAQ,CAAC,iBAAiB,CAAC,EAAE;QAAA,IAAAC,aAAA;QACtDH,YAAY,GAAG,UAAU,CAAAG,aAAA,GAAAZ,KAAK,CAACa,MAAM,cAAAD,aAAA,eAAZA,aAAA,CAAcf,IAAI,GAAGiB,IAAI,CAACC,KAAK,CAACf,KAAK,CAACa,MAAM,CAAChB,IAAI,CAAC,CAAChB,KAAK,GAAG,WAAW,0BAA0B;MAC9H,CAAC,MAAM;QACH4B,YAAY,GAAG,kBAAkBT,KAAK,CAACT,QAAQ,CAACM,IAAI,CAACG,KAAK,EAAE;MAChE;IACJ,CAAC,MAAM;MACHS,YAAY,GAAG,kBAAkBT,KAAK,CAACT,QAAQ,CAACyB,MAAM,IAAI;IAC9D;EACJ,CAAC,MAAM,IAAIhB,KAAK,CAACiB,OAAO,EAAE;IACtB;IACAR,YAAY,GAAG,0CAA0C;EAC7D,CAAC,MAAM;IACH;IACAA,YAAY,GAAG,WAAWT,KAAK,CAACF,OAAO,EAAE;EAC7C;EACA,MAAM,IAAIG,KAAK,CAACQ,YAAY,CAAC;AACjC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}